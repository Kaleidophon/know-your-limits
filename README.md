# Know Your Limits: Uncertainty Estimation with ReLU Classifiers Fails at Reliable OOD Detection

@TODO
* Add link to published paper
* Add citation 

This is the Github repository for the UAI 2021 of the same name, investigating 
how ReLU activation functions and the softmax function in neural classifiers 
This repository give an overview over findings, explain the repository structure and gives instruction on installation 
and usage. 

## Findings 

We build on previous research by Arora et al. (2018), showing that neural networks with piece-wise linear activation 
functions divide the feature space into polytopal regions, on which they can be expressed as an affine function. The 
plots below show the predictive entropy of a neural classifier on a synthetic multi-class classification problem (left)
as well as the polytopes it induces in the feature space (right; using the code of Jordan et al., 2019).

<p float="left">
    <img src="plots/uncertainty.png" width="40%" />
    <img src="plots/polytopes.png" width="40%" />
</p>

@TODO 




## Installation

@TODO 

## Repository Structure

@TODO

## Usage

@TODO

## Citation

If you are using any code in this repository or cite our work, please cite us using the 
information below:

@TODO

## Bibliography 

@TODO